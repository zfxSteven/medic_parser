# 医学语料分词
## 缘由
最近在做项目的时候，发现NER任务准确率不高且有边界问题，遂想了一个折中方案，将NER和分词结合了一下。  
为了提高分词精度，整理了不少专业词汇，由于涉及项目，词典不能放出来，但是我自己搭了个分词服务  
一方面方便平时的模型内部可视化；  
另一方面语料文本太少，分词在稳定性方面还学要提升；

## 项目
这次的主要是医疗文本的分词，词典是手工清洗过的，包含药品、疾病、治疗、检查检验等，共约1.1万词。后期会不定期更新词典。  
### 展示页面
[分词展示页面地址](http://parser.zfxstevenapi.site/parser)（特别丑，不要嫌弃。。。）  
### 调用代码 
Python3 
```python
# *_*coding:utf-8 *_*
import requests
import json

url = 'http://parser.zfxstevenapi.site/api'
data_json = {
    'dic_type': 'medic',
    'sen': '常染色体显性遗传，外显率60%，多发生于青少年或成年早期，平均发病年龄24岁，部分患者有热性惊厥或热性惊厥家族史，临床多表瑰为颞叶起源的部分性发作。 MRI多正常，部分有弥漫性点状T2高信号；连锁分析未发现与颞叶癫痫或热性惊厥已知位点相连锁。可选用卡马西平、苯妥英钠、丙戊酸钠治疗，预后良好。应注意与颞叶内侧癫痫相鉴别，后者平均发病年龄9岁，6%有热性惊厥史，少见有家族史，EEG常见局灶性痫样放电，MRI示海马T2高信号，通常比较难治。',
}
data_json = json.dumps(data_json, ensure_ascii=False)
r = requests.post(url, data=data_json.encode('utf-8'))
print(r.text)
```  
### 一点说明
大家不要车速太快，只是一个很小的VPS，已做速度限制，请文明驾驶。  
单句限制长度为1024个字符，每分钟最大请求数为20。  
有问题请联系我，大批量调用也请联系我  
邮箱：zfx050621@163.com  
